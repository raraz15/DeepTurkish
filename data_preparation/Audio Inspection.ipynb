{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen_clip(idx):\n",
    "    \n",
    "    audio_path = os.path.join(clips_dir,paths[idx]) \n",
    "    print(sentences[idx])\n",
    "    return ipd.Audio(audio_path)\n",
    "\n",
    "def clean_audio(audio):\n",
    "    \n",
    "    intervals = librosa.effects.split(audio, top_db=18, frame_length=4096, hop_length=2048)\n",
    "    no_intervals = intervals.shape[0]    \n",
    "        \n",
    "    if no_intervals == 1:       \n",
    "        cut_start_idx = intervals[0,0]\n",
    "        cut_end_idx = intervals[0,1]\n",
    "        \n",
    "    else:               \n",
    "        energies = np.zeros((no_intervals,))\n",
    "        for j in range(no_intervals):\n",
    "            \n",
    "            energies[j] = np.sum(np.square(audio[intervals[j,0]:intervals[j,1]]))\n",
    "        \n",
    "        max_energy = np.max(energies)\n",
    "        \n",
    "        relative_energies = 100*energies/max_energy\n",
    "                \n",
    "        high_energy_indices = []\n",
    "        for j,relative_energy in enumerate(relative_energies):\n",
    "            \n",
    "            if relative_energy> 10: # 10 percent found heuristicaly\n",
    "                high_energy_indices.append(j) # find which intervals have high energy\n",
    "        \n",
    "        first_interval_idx = high_energy_indices[0] # the first interval with high energy\n",
    "        last_interval_idx = high_energy_indices[-1] # last interval with high energy\n",
    "        \n",
    "        cut_start_idx = intervals[first_interval_idx,0] \n",
    "        cut_end_idx = intervals[last_interval_idx,1]\n",
    "        \n",
    "        \n",
    "    clean_audio = audio[cut_start_idx:cut_end_idx]\n",
    "        \n",
    "    return clean_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mozilla Turkish Dataset\n",
    "dataset_name = \"cv-corpus-5.1-2020-06-22\"\n",
    "\n",
    "dataset_dir = os.path.join(\"..\",\"data\",\"Datasets\",dataset_name,\"tr\")\n",
    "\n",
    "clips_dir = os.path.join(dataset_dir,\"clips\")\n",
    "\n",
    "pickle_dir = os.path.join(dataset_dir,\"cv-corpus-5.1-2020-06-22_validated_simple_ordered.pkl\") \n",
    "df = pd.read_pickle(pickle_dir)\n",
    "\n",
    "#annotation_df = pd.read_csv(tsv_dir,sep='\\t')\n",
    "#annotation_df = pd.read_csv(csv_dir)\n",
    "\n",
    "IDs = df[\"client_id\"]\n",
    "paths = df[\"path\"]\n",
    "sentences = df[\"sentence\"]\n",
    "codes = df['encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tt = \"test\"\n",
    "\n",
    "dataset_dir = os.path.join(\"..\",\"..\",\"Datasets\",\"ti20\",tt)\n",
    "\n",
    "clip_dir = os.path.join(dataset_dir,\"clean\")\n",
    "\n",
    "pickle_dir = os.path.join(dataset_dir,\"ti20_\"+tt+\"_coded.pkl\")\n",
    "\n",
    "df = pd.read_pickle(pickle_dir)\n",
    "\n",
    "paths = df[\"path\"]\n",
    "sentences = df[\"sentence\"]\n",
    "codes = df['encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#METUbet\n",
    "dataset_dir = os.path.join('..','..',\"Datasets\",\"METUbet\",\"data\")\n",
    "\n",
    "dataset_name = \"METUbet\"\n",
    "\n",
    "clip_dir = os.path.join(dataset_dir,'speech-text')\n",
    "pickle_dir = os.path.join(dataset_dir,'METUbet_encoded.pkl') # Original annotations\n",
    "\n",
    "df = pd.read_pickle(pickle_dir)\n",
    "\n",
    "#paths = df[\"path\"]\n",
    "sentences = df[\"turkish_sentence\"]\n",
    "codes = df['encoded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spectrogram Output Directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_spectrogram_dir = os.path.join(dataset_dir,\"spectrograms\",'amplitude')\n",
    "dB_spectrogram_dir = os.path.join(dataset_dir,\"spectrograms\",'dB')\n",
    "power_spectrogram_dir = os.path.join(dataset_dir,\"spectrograms\",'power')\n",
    "\n",
    "spectrogram_dirs = [amp_spectrogram_dir,dB_spectrogram_dir,power_spectrogram_dir]\n",
    "\n",
    "for d in spectrogram_dirs:\n",
    "    if not os.path.isdir(d):\n",
    "        os.makedirs(d)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single File Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 100\n",
    "listen_clip(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip_dir = os.path.join(dataset_dir,'speech-text','s1000','s1000-000.wav')\n",
    "idx = 100\n",
    "clip_dir = os.path.join(clips_dir,paths[idx])\n",
    "audio,sr = librosa.load(clip_dir,sr=16000)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "librosa.display.waveplot(audio, sr=sr, ax=ax) \n",
    "ax.set(title=\"{} Waveform\".format(paths[idx]))\n",
    "#plt.savefig(\"{} Waveform.png\".format(paths[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform_with_cuts(audio,sr,start_cut_time,end_cut_time,idx): #,amplitude_threshold\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    librosa.display.waveplot(audio, sr=sr, ax=ax) \n",
    "    ax.set(title=\"{} Waveform\".format(paths[idx]))\n",
    "\n",
    "    #plt.hlines(amplitude_threshold,0,len(audio),colors='r')\n",
    "    #plt.hlines(-amplitude_threshold,0,len(audio),colors='r')\n",
    "\n",
    "    bound = np.max(np.abs(audio))\n",
    "    \n",
    "    #plt.vlines(len(audio)/sr/3,-bound,bound,colors='b')\n",
    "    #plt.vlines(2*len(audio)/sr/3,-bound,bound,colors='b')\n",
    "\n",
    "    plt.vlines(start_cut_time,-bound,bound,colors='g')\n",
    "    plt.vlines(end_cut_time,-bound,bound,colors='g')\n",
    "    #plt.savefig(\"{} Cut.png\".format(paths[idx]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Spectrogram Variations for a Single Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(clips_dir,paths[1])\n",
    "audio,sr = librosa.load(audio_path,sr =44100)\n",
    " \n",
    "audio_clean = clean_audio(audio)\n",
    "\n",
    "amplitude_spectrogram = np.abs(librosa.stft(audio_clean,n_fft=512,hop_length=int(512/3),win_length=512))\n",
    "\n",
    "dB_spectrogram = librosa.amplitude_to_db(amplitude_spectrogram,np.max(amplitude_spectrogram))\n",
    "\n",
    "power_spectrogram = librosa.db_to_power(dB_spectrogram, ref=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "img = librosa.display.specshow(amplitude_spectrogram,\n",
    "                               y_axis='log', x_axis='time', ax=ax)\n",
    "ax.set_title('Amplitude spectrogram')\n",
    "#fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "#plt.text(18, 8000, sentences[1], fontsize=15,bbox=dict(alpha=1))\n",
    "\n",
    "#plt.savefig(\"Amplitude Spectrogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "img = librosa.display.specshow(dB_spectrogram,\n",
    "                               y_axis='log', x_axis='time', ax=ax)\n",
    "ax.set_title('dB spectrogram')\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "#plt.text(18, 9000, sentences[1], fontsize=14,bbox=dict(alpha=1))\n",
    "\n",
    "#plt.savefig(\"dB Spectrogram.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,8))\n",
    "img = librosa.display.specshow(power_spectrogram,\n",
    "                               y_axis='log', x_axis='time', ax=ax)\n",
    "ax.set_title('Power spectrogram')\n",
    "#plt.text(18, 8000, sentences[1], fontsize=13,bbox=dict(alpha=1))\n",
    "fig.colorbar(img, ax=ax, format=\"%+2.0f dB\")\n",
    "\n",
    "#plt.savefig(\"Power Spectrogram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Spectrogram Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create spectrograms and Write them to csv\n",
    "\n",
    "Read audio, clean it, calculate spectrograms and write to csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 590.10s\n",
      "Time: 641.59s\n",
      "Time: 690.73s\n",
      "Time: 667.50s\n",
      "Time: 611.72s\n",
      "Time: 587.86s\n",
      "Time: 644.11s\n",
      "Time: 661.13s\n",
      "Time: 683.43s\n",
      "Time: 658.77s\n",
      "Time: 643.85s\n",
      "Time: 597.68s\n",
      "Time: 621.28s\n",
      "Time: 626.61s\n",
      "Time: 652.88s\n",
      "Time: 669.46s\n",
      "Time: 644.78s\n",
      "Time: 626.91s\n",
      "Time: 635.84s\n",
      "Time: 619.86s\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "start_time = time.time()\n",
    "audio_lengths = []\n",
    "\n",
    "for root,_,files in os.walk(clips_dir):\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        if file in paths and file.split('.')[-1] in ['wav','mp3']:\n",
    "\n",
    "            audio_path = os.path.join(root,file)\n",
    "\n",
    "            audio,sr = librosa.load(audio_path,sr=16000)\n",
    "            \n",
    "            audio_clean = clean_audio(audio)\n",
    "            \n",
    "            audio_lengths.append(len(audio_clean))\n",
    "\n",
    "            amplitude_spectrogram = np.abs(librosa.stft(audio_clean,n_fft=512,hop_length=int(512/3),win_length=512))\n",
    "            dB_spectrogram = librosa.amplitude_to_db(amplitude_spectrogram,np.max(amplitude_spectrogram))\n",
    "            power_spectrogram = librosa.db_to_power(dB_spectrogram, ref=1.0)           \n",
    "\n",
    "            file_name = file.split(\".\")[0]+\".csv\"\n",
    "            np.savetxt(os.path.join(amp_spectrogram_dir,file_name),amplitude_spectrogram,delimiter=',')\n",
    "            np.savetxt(os.path.join(dB_spectrogram_dir,file_name),dB_spectrogram,delimiter=',')\n",
    "            np.savetxt(os.path.join(power_spectrogram_dir,file_name),power_spectrogram,delimiter=',')\n",
    "\n",
    "            counter += 1        \n",
    "            if counter == 1000:\n",
    "                print(\"Time passed: {:.2f}s\".format(time.time()-start_time))\n",
    "                counter = 0\n",
    "                start_time = time.time()\n",
    "                \n",
    "print('Total audio length {:.2f} hours'.format(sum(audio_lengths)/sr/60/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\..\\\\Datasets\\\\cv-corpus-5.1-2020-06-22\\\\tr\\\\spectrograms\\\\dB'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dB_spectrogram_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 92.93 mins\n"
     ]
    }
   ],
   "source": [
    "spectrogram_dirs = [dB_spectrogram_dir]\n",
    "for d in spectrogram_dirs:\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    output_filename = '{}_{}_spectrograms.tar.gz'.format(dataset_name,d.split(\"\\\\\")[-1])   \n",
    "    \n",
    "    output_dir = os.path.join(dataset_dir,\"spectrograms\",output_filename)\n",
    "\n",
    "    with tarfile.open(output_dir, \"w:gz\") as tar:\n",
    "        tar.add(d, arcname=os.path.basename(d))\n",
    "\n",
    "    print(\"Total time: {:.2f} mins\".format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path_list = [p.split('.')[0] for p in paths.tolist()]\n",
    "\n",
    "for spec_dir in spectrogram_dirs:\n",
    "    \n",
    "    for root,_,files in os.walk(spec_dir):\n",
    "\n",
    "        for file in files:\n",
    "\n",
    "            if file.split('.')[0] not in path_list:\n",
    "                \n",
    "                file_path = os.path.join(root,file)\n",
    "                os.remove(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start_time = time.time()\n",
    "\n",
    "output_filename = \"dB_spectrograms.tar.gz\"\n",
    " \n",
    "with tarfile.open(output_filename, \"w:gz\") as tar:\n",
    "    tar.add(spectrogram_dir, arcname=os.path.basename(spectrogram_dir))\n",
    "    \n",
    "print(\"Total time: {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcription lengts of the sentences.\n",
    "lengths = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    lengths.append(len(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Duration calculations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "duration = []\n",
    "\n",
    "for idx,path in enumerate(paths):\n",
    "    \n",
    "    audio_path = os.path.join(clip_dir,path)\n",
    "    \n",
    "    audio,sr = librosa.load(audio_path)\n",
    "    \n",
    "    duration.append(len(audio)/sr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = 0\n",
    "for dur in duration:\n",
    "    tot += dur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = paths[0].split(\".\")[0]+\".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = os.path.join(clip_dir,paths[0])\n",
    "audio,sr = librosa.load(audio_path)\n",
    "\n",
    "amplitude_spectrogram = np.abs(librosa.stft(audio,n_fft=512))\n",
    "\n",
    "dB_spectrogram = librosa.amplitude_to_db(amplitude_spectrogram,np.max(amplitude_spectrogram))\n",
    "\n",
    "power_spectrogram = librosa.db_to_power(dB_spectrogram, ref=1.0)\n",
    "\n",
    "np.savetxt(name,power_spectrogram,delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
